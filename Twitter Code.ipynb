{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Network construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import igraph as ig\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import scipy.stats as st\n",
    "import pickle\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/csvs/table_retweets.csv', low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy without NaN value -> kept only retweets\n",
    "data_retweet = data[data['retweeted_status.user.id'].isnull() == False].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding columns for date, weight and a day counter\n",
    "data_retweet['date'] = data_retweet['created_at'].apply(lambda x: x[5:10])\n",
    "data_retweet['weight'] = 1\n",
    "data_retweet['day_count'] = data_retweet.groupby('date').ngroup().values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  retweets distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_per_day = data_retweet.groupby('date',as_index=False).count()\n",
    "\n",
    "plt.xlabel('date')\n",
    "plt.ylabel('number of tweets')\n",
    "plt.title('Tweets per Day')\n",
    "plt.xticks(count_per_day.index,count_per_day.date, rotation= 'vertical')\n",
    "plt.bar(count_per_day.index,count_per_day.id_str)\n",
    "plt.savefig('measures/pics/retweet_per_day.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fuction to generate graph of a selected period\n",
    "def build_graph(data_retweet, fini_day,init_day = 0):\n",
    "    sub_set = data_retweet[(data_retweet.day_count >= init_day)&(data_retweet.day_count < fini_day)]\n",
    "    db_for_network = sub_set.groupby(['retweeted_status.user.id','user.id'], as_index=False).count()\n",
    "    db_for_network = db_for_network[db_for_network.weight > 1]#.astype(int)\n",
    "    return ig.Graph.TupleList(db_for_network[['retweeted_status.user.id','user.id','weight']].itertuples(index=False), directed=True, weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Centrality measures analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to compute centrality measures\n",
    "def centrality_measures(graph, df, weights = None):\n",
    "    # graph = igraph.Graph object\n",
    "    # df = pandas.DataFrame object\n",
    "    df['name'] = graph.vs['name']\n",
    "    df['betweenness'] = graph.betweenness(weights=weights)\n",
    "    df['pagerank'] = graph.pagerank(weights=weights)\n",
    "    df['degree'] = graph.degree()\n",
    "    df['outdegree'] = graph.outdegree()\n",
    "    df['local_transitivity'] = graph.transitivity_local_undirected(mode = 'zero',weights=weights)\n",
    "    if graph.is_simple():\n",
    "        df['knn'] = graph.knn(weights=weights)[0]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  operations for merging the csv dataset with a new pickle file with metadata about the twits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new pickle file with raw metadata\n",
    "with open('data/pickles/df_metadata.pickle','rb') as f:\n",
    "    df_meta=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning metadata, deleting NaN value, keeping only retweeted_username from the text \n",
    "with open('data/pickles/short_df.pickle','wb') as file:\n",
    "    df_meta = df_meta[df_meta['retweeted_status.id'].isnull() == False]\n",
    "    df_meta.text = df_meta['text'].astype(str).apply(lambda x: x.split(' ')[1])\n",
    "    df_meta['text']=df_meta['text'].apply(lambda x: x.split('@')[1].split(':')[0])\n",
    "    df_meta = df_meta.rename(columns = {'text':'retweeted_username'})\n",
    "    pickle.dump(df_meta[['id_str','retweeted_username','retweeted_status.id','user.screen_name','user.followers_count']],file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging inital data with these new metadata\n",
    "new_df = data_retweet.merge(df_meta[['id_str','retweeted_username','user.screen_name']].astype(str), on = 'id_str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving new database\n",
    "with open('complete_df.pickle','wb') as f:\n",
    "    pickle.dump(new_df,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  now I shotdown the kernel to free space on ram, then reload the ultimate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reload data from a pickle file\n",
    "with open('data/pickles/complete_df.pickle','rb') as f:\n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3 days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g3 = build_graph_by_day(df, 4, init_day=1)\n",
    "df3 = centrality_measures(g3, pd.DataFrame(), weights = 'weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  7 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g7= build_graph_by_day(df, 8, init_day=1)\n",
    "df7 = centrality_measures(g7, pd.DataFrame(), weights = 'weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  15 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g15= build_graph_by_day(df, 16, init_day=1)\n",
    "df15 = centrality_measures(g15, pd.DataFrame(), weights = 'weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  30 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g30= build_graph_by_day(df, 31, init_day=1)\n",
    "df30 = centrality_measures(g30, pd.DataFrame(), weights = 'weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting results\n",
    "name = ['df3','df7','df15','df30']\n",
    "i=0\n",
    "for dataframe in [df3,df7,df15,df30]:\n",
    "    fig, axs = plt.subplots(2, 1, sharex=True)\n",
    "    sns.regplot(data = dataframe.sort_values('outdegree',ascending=False)[:1000], x = 'outdegree', y = 'betweenness', ax = axs[0])\n",
    "    sns.regplot(data = dataframe.sort_values('outdegree',ascending=False)[:1000], x = 'outdegree', y = 'knn', ax = axs[1])\n",
    "    fig.savefig('measures/pics/measurestrends%s.png'%name[i])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pagerank vs outdegree\n",
    "plt.ylim((-0.001,0.003))\n",
    "plt.ticklabel_format(axis='y', style='sci', scilimits=(0,0))\n",
    "sns.scatterplot(data = prova, x = 'outdegree', y = 'pagerank')\n",
    "plt.savefig('measures/pics/pagerank_vs_degree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clustering coefficient vs outdegree\n",
    "sns.scatterplot(data = prova, x = 'outdegree', y = 'local_transitivity')\n",
    "plt.savefig('cc_vs_degree.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  outdegree distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_tot = build_graph_by_day(df,31)\n",
    "outk = np.array(g_tot.outdegree())\n",
    "outk = outk[np.where(outk>0)] #remove the zero values to not have problems to pass in log scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data = outk, log_scale=(True,True))\n",
    "plt.title('Distribution of Out-degree')\n",
    "plt.xlabel('k out')\n",
    "plt.savefig('measures/pics/out_distr.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  fitting the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerlaw(x, m, c):\n",
    "    return  x*m + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata = np.log10(np.histogram(outk, bins= 50)[1][1:])\n",
    "ydata = np.log10(np.where(np.histogram(outk, bins=50)[0]!=0,np.histogram(outk, bins=50)[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popt, pcov = optimize.curve_fit(powerlaw,xdata,ydata, p0 = [-3, 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(xdata,ydata, alpha=0.8, label = 'k distribution')\n",
    "plt.plot(xdata, popt[0]*xdata + popt[1], c='r', label = 'fitting curve')\n",
    "plt.xlabel('log(k)')\n",
    "plt.ylabel('log(counts)')\n",
    "plt.suptitle('K ditribution fitting')\n",
    "plt.title('\\u03B1 = %.2f'%popt[0])\n",
    "plt.legend()\n",
    "plt.savefig('measures/pics/fitting_distr.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Leader detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#users id of to retweeted of each set\n",
    "top_100_k = pd.DataFrame({'30_days' : measures_30_days.sort_values('outdegree')['name'].values[-100:],\n",
    "                            '15_days' : measures_first_2_week.sort_values('outdegree')['name'].values[-100:],\n",
    "                            '7_days' : measures_7_days.sort_values('outdegree')['name'].values[-100:],\n",
    "                            '3_days' : measures_3_days.sort_values('outdegree')['name'].values[-100:]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count number of appearences\n",
    "from collections import Counter\n",
    "counter_k = Counter(np.concatenate([i for i in top_100_k.values]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results\n",
    "plt.hist(list(counter_k.values()),  bins= np.linspace(0.5,4.5,5))\n",
    "plt.xticks([1,2,3,4])\n",
    "plt.suptitle('Number of appearances in different sets', fontsize = 18, y =1.01)\n",
    "plt.title('top 100 leaders in outdegree')\n",
    "plt.xlabel('num of appearances')\n",
    "plt.savefig('measures/pics/outdegree_counter.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fucntion to build a network starting from 3 random days\n",
    "def build_graph_3rand(data_retweet,days_choice=None):  \n",
    "    if days_choice.any()!=None:\n",
    "        sub_set = data_retweet[data_retweet.day_count.isin(days_choice)]\n",
    "    else:\n",
    "        sub_set=data_retweet\n",
    "    db_for_network = sub_set.groupby(['retweeted_status.user.id','user.id'], as_index=False).count()\n",
    "    db_for_network = db_for_network[db_for_network.weight > 1]\n",
    "    return ig.Graph.TupleList(db_for_network[['retweeted_status.user.id','user.id','weight',]].itertuples(index=False), directed=True, weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_count = df['day_count'].unique() #variabile con i numeri dei giorni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_graphs = [] # costruisco 20 network doi 3 giorni random\n",
    "for i in range(20):\n",
    "    random_graphs.append(build_graph_3rand(df,np.random.choice(days_count,3,replace=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs_df = []  #costruisco i loro rispettivi dataframe con name e  degree \n",
    "for g in random_graphs:\n",
    "    graphs_df.append(pd.DataFrame({'name' : g.vs['name'], 'outdegree' : g.outdegree()}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(np.concatenate(graphs_leader))\n",
    "\n",
    "\n",
    "plt.hist(list(counter.values()), bins= np.linspace(0.5,20.5,21))\n",
    "plt.xticks(range(1,21))\n",
    "plt.suptitle('number of random network in which the user appears as leaders', fontsize = 12)\n",
    "plt.savefig('measures/pics/number_leaders_rand_graph.png')\n",
    "plt.show()#results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Network evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first half of the month\n",
    "graphs_first_15  = []\n",
    "for day in range(2,16):\n",
    "    graphs_first_15.append(build_graph_by_day(df, day, init_day=1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giant_connected_component_dimension = []\n",
    "relative_gcc_dimension = []\n",
    "for g in graphs_first_15:\n",
    "    cl = g.components(mode='WEAK') #STRONG means that each pair of vertex must be reachable from each other\n",
    "    giant_connected_component_dimension.append(len(cl.giant().vs)) # dimensione totale\n",
    "    relative_gcc_dimension.append(len(cl.giant().vs)/len(g.vs))  # dimensione relativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#second half\n",
    "graphs_last_15  = []\n",
    "for day in range(17,31):\n",
    "    graphs_last_15.append(build_graph_by_day(df, day, init_day=16))\n",
    "    \n",
    "giant_connected_component_dimension_bis = []\n",
    "relative_gcc_dimension_bis = []\n",
    "for g in graphs_last_15:\n",
    "    cl = g.components(mode='WEAK') \n",
    "    giant_connected_component_dimension_bis.append(len(cl.giant().vs))\n",
    "    relative_gcc_dimension_bis.append(len(cl.giant().vs)/len(g.vs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results\n",
    "fig,ax2 = plt.subplots(1,1,figsize = (8,6))\n",
    "ax2.plot(relative_gcc_dimension,label='first period')\n",
    "ax2.plot(relative_gcc_dimension_bis, label='last period')\n",
    "ax2.set_title('relative dimension of the biggest connecetd component')\n",
    "ax2.set_ylabel('n_cgg/n_tot')\n",
    "ax2.set_xlabel('days of the network')\n",
    "ax2.set_xticks(range(14))\n",
    "ax2.set_xticklabels(range(2,17))\n",
    "ax2.legend()\n",
    "fig.savefig('measures/pics/size_change_gcc(days).png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Cluster Ananlysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_tot.to_undirected(combine_edges='sum')  #making total graph as undirected\n",
    "\n",
    "#now as cluster\n",
    "cl_tot = g_tot.community_multilevel(weights='weight', return_levels=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = cl_tot.subgraphs()   # lista con i grafi delle singole componenti\n",
    "clusters_size = [cl.vcount() for cl in clusters]  #lista con il numero di utenti di ogni componente\n",
    "components_df = pd.DataFrame({'cluster' : clusters, 'size' : clusters_size})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_component_df = components_df.sort_values('size',ascending=False)['cluster'] \n",
    "#ordinato per dimensione della community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same algorithm, now done for each week\n",
    "four_graphs = [build_graph_by_day(df, init_day=1+7*i, fini_day= 7*(i+1)+1) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "as_cluster = [] # array with vertex clustering objects\n",
    "for g in four_graphs:\n",
    "    g.to_undirected(combine_edges='sum')\n",
    "    as_cluster.append(g.community_multilevel(weights='weight', return_levels=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs_components= [] # for each week I save the siza of clusters\n",
    "for cl in as_cluster:\n",
    "    clusters = cl.subgraphs()\n",
    "    clusters_lenght = [c.vcount() for c in clusters]\n",
    "    graphs_components.append(pd.DataFrame({'cluster' : clusters, 'size' : clusters_lenght}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorting database\n",
    "df_sorted = [graphs_components[i].sort_values('size', ascending = False) for i in range(4)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notiziari_id = [] #lista con gli id degli utenti facenti parte la community \"notiziari\"\n",
    "for i in leader_list: \n",
    "    if np.isin(i,sorted_component_df.values[0].vs['name']): #values[0] corrisponde alla più grande community, della rete totale\n",
    "        notiziari_id.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notiziari_size = [] # salvo qui le dimensione del cluster notiziari nei 4 periodi\n",
    "for data in df_sorted:\n",
    "    for i in range(5): #cerco la comnità notiziari tra le prime 5 di ogni periodo, suppendo ci sia\n",
    "        if  len(np.intersect1d(notiziari_id, data.iloc[i,0].vs['name'], assume_unique=True)) > 5 : \n",
    "            #ipotizzo che bastino 5 utenti della lista per riconoscere la comunità\n",
    "            notiziari_size.append(data.iloc[i,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same for virologists\n",
    "virologi_id = []\n",
    "for i in leader_list:  \n",
    "    if np.isin(i,sorted_component_df.values[1].vs['name']):\n",
    "        virologi_id.append(i)\n",
    "virologi_size = []\n",
    "for data in df_sorted:\n",
    "    for i in range(5):\n",
    "        if  len(np.intersect1d(virologi_id, data.iloc[i,0].vs['name'], assume_unique=True)) == 2 : #==2 perchè cerco Burioni e Cartabellotta \n",
    "            virologi_size.append(data.iloc[i,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#politicians\n",
    "destra_id = []\n",
    "for i in leader_list: \n",
    "    if np.isin(i,components_df.sort_values('size',ascending=False)['cluster'].values[2].vs['name']):\n",
    "        destra_id.append(i)\n",
    "destra_size = []\n",
    "for data in df_sorted:\n",
    "    for i in range(5): \n",
    "        if  len(np.intersect1d(destra_id, data.iloc[i,0].vs['name'], assume_unique=True)) > 5 : \n",
    "            destra_size.append(data.iloc[i,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result\n",
    "plt.plot(notiziari_size, label = 'news companies')\n",
    "plt.plot(virologi_size, label = 'virologists')\n",
    "plt.plot(destra_size, label = 'right wing')\n",
    "plt.ylabel('number of verteces')\n",
    "plt.xticks(range(4), ['%d° period'%i for i in range(1,5)])\n",
    "plt.legend()\n",
    "plt.savefig('measures/pics/community_for_each_week.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  the same is done but for a cumulative analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "four_graphs = [build_graph_by_day(df, init_day=1, fini_day=7*(1+i)+1) for i in range(4)]\n",
    "\n",
    "as_cluster = [] # li trasoformo tutti in vertex_clustrering objects\n",
    "for g in four_graphs:\n",
    "    g.to_undirected(combine_edges='sum')\n",
    "    as_cluster.append(g.community_multilevel(weights='weight', return_levels=False))\n",
    "    \n",
    "graphs_components= [] # e ora di ogni priodo divido il grafico in clusters di ccui salvo la dimensione\n",
    "for cl in as_cluster:\n",
    "    clusters = cl.subgraphs()\n",
    "    clusters_lenght = [c.vcount() for c in clusters]\n",
    "    graphs_components.append(pd.DataFrame({'cluster' : clusters, 'size' : clusters_lenght}))\n",
    "\n",
    "#riordine i database dei users in ordine di dimensione\n",
    "df_sorted = [graphs_components[i].sort_values('size', ascending = False) for i in range(4)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notiziari_size = [] # salvo qui le dimensione del cluster notiziari nei 4 periodi\n",
    "for data in df_sorted:\n",
    "    for i in range(5): #cerco la comnità notiziari tra le prime 5 di ogni periodo, suppendo ci sia\n",
    "        if  len(np.intersect1d(notiziari_id, data.iloc[i,0].vs['name'], assume_unique=True)) > 5 : \n",
    "            #ipotizzo che bastino 5 utenti della lista per riconoscere la comunità\n",
    "            notiziari_size.append(data.iloc[i,1])\n",
    "virologi_size = []\n",
    "for data in df_sorted:\n",
    "    for i in range(5):\n",
    "        if  len(np.intersect1d(virologi_id, data.iloc[i,0].vs['name'], assume_unique=True)) == 2 : #==2 perchè cerco Burioni e Cartabellotta \n",
    "            virologi_size.append(data.iloc[i,1])\n",
    "destra_size = []\n",
    "for data in df_sorted:\n",
    "    for i in range(5): \n",
    "        if  len(np.intersect1d(destra_id, data.iloc[i,0].vs['name'], assume_unique=True)) > 5 : \n",
    "            destra_size.append(data.iloc[i,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize = (7,5))\n",
    "ax.plot(notiziari_size, label = 'news companies')\n",
    "ax.plot(virologi_size, label = 'virologists')\n",
    "ax.plot(destra_size, label = 'right wing')\n",
    "ax.set_ylabel('number of verteces')\n",
    "ax.set_xticks(range(4), ['%d° period'%i for i in range(1,5)])\n",
    "ax.legend()\n",
    "fig.savefig('measures/pics/community_change.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
